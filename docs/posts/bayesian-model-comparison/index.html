<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-11-19">

<title>Passing Thoughts - Bayesian comparison of cross-validated algorithms</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Passing Thoughts</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ergodicedamame/blog/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#problem-statement" id="toc-problem-statement" class="nav-link active" data-scroll-target="#problem-statement">Problem statement</a></li>
  <li><a href="#corani-and-benavolis-bayesian-correlated-t-test" id="toc-corani-and-benavolis-bayesian-correlated-t-test" class="nav-link" data-scroll-target="#corani-and-benavolis-bayesian-correlated-t-test">Corani and Benavoli’s Bayesian correlated t-test</a></li>
  <li><a href="#time-to-code-this-up" id="toc-time-to-code-this-up" class="nav-link" data-scroll-target="#time-to-code-this-up">Time to code this up!</a></li>
  <li><a href="#cost-sensitive-decisions" id="toc-cost-sensitive-decisions" class="nav-link" data-scroll-target="#cost-sensitive-decisions">Cost sensitive decisions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Bayesian comparison of cross-validated algorithms</h1>
<p class="subtitle lead">Model selection via a Bayesian correlated t-test.</p>
  <div class="quarto-categories">
    <div class="quarto-category">ML</div>
    <div class="quarto-category">Theory</div>
    <div class="quarto-category">Model evaluation</div>
    <div class="quarto-category">Bayesian</div>
    <div class="quarto-category">Cross-validation</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 19, 2022</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>Robust model evaluation should be second nature for those of us that work with data and predictive models. When determining whether one model is better than another, there are many techniques that one can use. Very common ones include <em>bootstrapping</em> and <em>cross-validation</em>.</p>
<p>First and foremost however, one must make a decision as to what “better” means. Better in what way? More accurate? Faster? More (budget) efficient? We will revisit this later. For now, let’s assume that better means “obtains a higher F1 score”. F1 is just an example, and we could consider any other score. Once we have decided to say that the model with the highest F1 score is better, the more serious question arises: how do we know whether a model is indeed better? Can we just take an average score across a test set and compare the numbers, i.e.&nbsp;plain-old pointwise comparison? I think we agree that we would like something more robust and which, ideally, takes uncertainty into account.</p>
<div class="page-columns page-full"><p>We ideally want to have a probability distribution which informs us, in some way, what the probability of one model being better than the other is. That is, we want something like <span class="math inline">\(P(M_1 &gt; M_2 | D)\)</span>, where <span class="math inline">\(M_1 &gt; M_2\)</span> denotes that model <span class="math inline">\(M_1\)</span> is better than model <span class="math inline">\(M_2\)</span> and <span class="math inline">\(D\)</span> is the data used for the comparison. In fact, we may want to do more than that. Ideally, we would like a distribution over the true performance difference of the two algorithms. What a great motive to enter the wonderful world of <em>Bayesian modelling</em><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p><div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;See, e.g. <span class="citation" data-cites="kruske2013best">Kruske (<a href="#ref-kruske2013best" role="doc-biblioref">2013</a>)</span>, for a nice, rapid tour of Bayesian modelling for group comparisons.</p></li></div></div>
<section id="problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="problem-statement">Problem statement</h2>
<p>Assume that we are interested in comparing the performance (e.g.&nbsp;accuracy, recall, precision, <span class="math inline">\(\text{F}_{\beta}\)</span>, etc.) of two predictors. If using cross-validation, <span class="citation" data-cites="bouckaert2003choosing">Bouckaert (<a href="#ref-bouckaert2003choosing" role="doc-biblioref">2003</a>)</span> recommends making this more robust (i.e.&nbsp;returning more stable statistics) by using <em>repeated cross-validation</em>; that is performing evaluation via <span class="math inline">\(m\)</span> repetitions of <span class="math inline">\(k\)</span>-fold cross-validation. Both classifiers will be trained on the same data and tested on the same data and we can therefore collect the <em>differences of their performances</em></p>
<p><span class="math display">\[
\delta = \{\delta_{1}, \delta_{2},. . ., \delta_{n}\}
\]</span></p>
<p>where <span class="math inline">\(n=mk\)</span>. Denote the sample mean and sample variance of the differences as <span class="math inline">\(\hat{\delta}\)</span> and <span class="math inline">\(\hat{\sigma}^{2}\)</span>.</p>
<p>What can we say about these samples? Well, one thing is that these samples are almost certainly <em>noisy</em> observations of an underlying true difference of performance between the two algorithms. That is, there exist a hidden performance difference which we don’t know but that manifest itself, with noise, through these samples. For instance, if we assume that the <span class="math inline">\(\delta_{i}\)</span> s are i.i.d. then we could say that the <span class="math inline">\(\delta_{i}\)</span> are samples from a distribution with a true underlying mean, which would be the mean of interest to us. We could then further assign a prior distribution to that true mean (and any other parameters in the specification of the sampling distribution) and, after observing some samples, perform inference to construct the posterior distribution over the true mean, given the observed data. This is the standard paradigm of Bayesian modelling.</p>
<p>There are infinite ways to model such a process but we can follow the aphorism, gifted to us by <a href="https://en.wikipedia.org/wiki/All_models_are_wrong_">George Box</a>, that none of them will be correct, but some of them may be useful. In particular, the assumtions that we bake into the model will make the model more or less useful. Oversimplifying assumptions would lead us to a model that is not able to describe the underlying process. Complex interactions would lead to a model that is intractable. Of course these days, with powerful probabilist programming languages, it is much easier to build a complex model and have a black-box inference algorithm that will give us results. This, however, isn’t a free meal. Complex models, especially hierachical ones, lead to complex inference processes that require expertise to diagnose. Moreover, the choce of priors will also become a delicate issue.</p>
<p>In general, we need to balance two things:</p>
<ol type="1">
<li>the modelling assumptions,</li>
<li>the techniques to perform inference, i.e.&nbsp;the computational techniques.</li>
</ol>
<p>In the case that we are considering here, i.e.&nbsp;comparing models across cross-validation scores, one important modelling aspect is that the scores are not independent: in fact the resulting models will have an overlapping training set and an overlapping testing set.</p>
<p>In this post, we will be presenting a model that was developed in <span class="citation" data-cites="corani2015bayesian">Corani and Benavoli (<a href="#ref-corani2015bayesian" role="doc-biblioref">2015</a>)</span>. This is a relatively simple model which uses the properties of exponential families and conjugacy to simplify inference. Note that this is just <em>one</em> possible model of the process, and it is by no means the best model!</p>
</section>
<section id="corani-and-benavolis-bayesian-correlated-t-test" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="corani-and-benavolis-bayesian-correlated-t-test">Corani and Benavoli’s Bayesian correlated t-test</h2>
<p>The model proposed by <span class="citation" data-cites="corani2015bayesian">Corani and Benavoli (<a href="#ref-corani2015bayesian" role="doc-biblioref">2015</a>)</span> is as follows. Assume that the observations <span class="math inline">\(\delta_i\)</span>, are <strong>identically distributed but <em>dependent</em></strong>. Specifically, let the observations have the same mean, <span class="math inline">\(\mu\)</span>, the same precision, <span class="math inline">\(\nu,\)</span> and be equally correlated with each other with correlation <span class="math inline">\(\rho &gt; 0\)</span>. This is the case when the <span class="math inline">\(n\)</span> observations are the <span class="math inline">\(n\)</span> differences of performance between two predictors yielded by cross-validation. The data generation process is then modelled as:</p>
<p><span class="math display">\[
\delta = I_{n \times 1}\mu + v
\]</span></p>
<p>where <span class="math inline">\(v\)</span> is a noise vector with zero mean and covariance matrix <span class="math inline">\(\Sigma_{n \times n}\)</span> with the following structure: each diagonal element equals <span class="math inline">\(\sigma^{2} = 1/\nu\)</span>; non-diagonal elements equal <span class="math inline">\(\rho \sigma^{2}\)</span>. This is knows as the <em>interclass covariance matrix</em>.</p>
<p>Define <span class="math inline">\(\Sigma = \sigma^{2} M\)</span> with <span class="math inline">\(M\)</span> an <span class="math inline">\((n \times n)\)</span> correlation matrix, e.g.&nbsp;in <span class="math inline">\(3d\)</span></p>
<p><span class="math display">\[
M =
  \left[ {\begin{array}{cc}
    1 &amp; \rho &amp; \rho \\
    \rho &amp; 1 &amp; \rho\\
    \rho &amp; \rho &amp; 1\\
  \end{array} } \right]
\]</span></p>
<p><span class="citation" data-cites="nadeaubengio2003">Nadeau and Bengio (<a href="#ref-nadeaubengio2003" role="doc-biblioref">2003</a>)</span> show that the correlation between the cross-validation results is positive and therefore, since <span class="math inline">\(\sigma^{2} &gt; 0\)</span>, <span class="math inline">\(\Sigma\)</span> is invertible and positive definite.</p>
<p>With this we have the basic ingredient indicating how we want to model the interactions between the samples, however we still need to define a generative process; a prior over <span class="math inline">\(\mu\)</span> (the quantity of interest) and a likelihood (i.e.&nbsp;a sampling distribution). For the sampling distribution of correlated observations assume the noise vector, <span class="math inline">\(v\)</span>, to be distributed as a multivariate Normal distribution:</p>
<p><span class="math display">\[
P(\delta| \mu, \Sigma) = \frac{
  \exp(-\frac{1}{2}(\delta - I\mu)^{T}\Sigma^{-1}(\delta - I\mu))}
  {(2\pi)^{n/2}\sqrt{|\Sigma|}}
\]</span></p>
<p>We ultimately want a distribution over <span class="math inline">\(\mu\)</span>. We could go about this by defining priors over the three parameters, <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma^{2}\)</span> and <span class="math inline">\(\rho\)</span>, and inferring the posterior over these. The approach taken by the authors here is simpler and, importantly, allows us to get the posterior in closed form. This is achieved by avoiding the need to estimate <span class="math inline">\(\rho\)</span> through use of the Nadeau-Bengio heuristic estimate for the correlation.</p>
<p>Specifically Nadeau and Bengio propose to take <span class="math inline">\(\rho = \frac{n_{\text{test}}}{n_{\text{total}}}\)</span>, where <span class="math inline">\(n_{\text{test}}\)</span> is the size of the test set and <span class="math inline">\(n_{\text{total}} = n_{\text{test}} + n_{\text{train}}\)</span>, i.e.&nbsp;the total dataset size.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
The idea behind the choice of correlation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>See <span class="citation" data-cites="nadeaubengio2003">Nadeau and Bengio (<a href="#ref-nadeaubengio2003" role="doc-biblioref">2003</a>)</span> sections 3 and 5 for details. The main points and heuristics behind this choice for the correlation factor are:</p>
<ul>
<li><p>The real <span class="math inline">\(\rho\)</span> is unknown, in fact usually this is just set to <span class="math inline">\(0\)</span> meaning that correlation is not accounted for. This can lead to underestimates of the estimated variance. In the paper the authors propose <span class="math inline">\(\rho=\frac{n_{\text{test}}}{n_{\text{total}}}\)</span>. Note that this choice, as stated by the authors, is a gross approximation. Yet it is better than pretending that <span class="math inline">\(\rho=0\)</span>.</p></li>
<li><p>The choice is made with an important assumption – that the specific training instances don’t matter, just the training set size. This is a very strong assumption and one that isn’t generically justified.</p></li>
<li><p>This correction is good for stable algorithms (<em>c.f.</em> the point above), i.e.&nbsp;ones that are not too sensitive to perturbation of the training set. Or for algorithms with low capacity compared to training set size.</p></li>
<li><p>The idea is that the correlation should reduce as more training data is used. More training data should stabilise the algorithm. That is, as the data size increases the model should approach saturation and, therefore, as we keep adding data the resulting decision function shouldn’t change too much.</p></li>
</ul>
</div>
</div>
</div>
<p>Okay, so now we’re in business! With <span class="math inline">\(\rho\)</span> fixed we can infer the posterior over <span class="math inline">\(\mu\)</span>.</p>
<p>Choose the joint prior for the mean and precision parameters of the Normal distribution to be</p>
<p><span class="math display">\[P(\mu, \nu | \mu_{0}, k_{0}, a, b) = NG(\mu, \nu; \mu_{0}, k_{0}, a, b)
\]</span></p>
<p>where <span class="math inline">\(NG\)</span> is the standard Normal-Gamma. This is a <a href="https://en.wikipedia.org/wiki/Normal-gamma_distribution"><em>conjugate prior</em></a>, to the normal, which makes modelling easier.</p>
<p>Because of the conjugacy, the posterior over <span class="math inline">\(\{\mu, \nu\}\)</span> will also be a Normal-Gamma, i.e.</p>
<p><span class="math display">\[
P(\mu, \nu| \delta, \mu_{0}, k_{0}, a, b, \rho) = NG(\mu, \nu; \tilde{\mu}_{n}, \tilde{k}_{n}, \tilde{a}_{n}, \tilde{b}_{n})
\]</span></p>
<p>We are interested in the distribution over <span class="math inline">\(\mu\)</span>. In order to obtain that, we have to marginalise over <span class="math inline">\(\nu\)</span>. Doing so results in a Student’s t-distribution for <span class="math inline">\(\mu\)</span> <span class="citation" data-cites="corani2015bayesian">(<a href="#ref-corani2015bayesian" role="doc-biblioref">2015</a>)</span></p>
<p><span class="math display">\[
P(\mu|\delta, \mu_{0}, k_{0}, a, b, \rho) = St(\mu; 2\tilde{a}_{n}, \tilde{\mu}_{n}, \frac{\tilde{b}_{n}\tilde{k}_{n}}{\tilde{a}_{n}})
\]</span></p>
<div class="page-columns page-full"><p>The expression for the parameters of the Student distribution are a little unwieldy, however if we use what is called a <em>matching prior</em><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> then this is simplified. We use the matching prior given by <span class="math inline">\(\mu_{0} = 0\)</span>, <span class="math inline">\(k_{0} \rightarrow \infty\)</span>, <span class="math inline">\(a = -1/2\)</span> and <span class="math inline">\(b = 0\)</span> to get:</p><div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;A <em>matching prior</em> is a prior for which posterior probability statements about the parameter also have an interpretation as confidence statements in the sampling model; i.e.&nbsp;the posterior will return properties that match the frequentist’s analysis.</p></li></div></div>
<p><span class="math display">\[
St(\mu; n - 1, \hat{\delta}, (\frac{1}{n} + \frac{\rho}{1 - \rho})\hat{\sigma}^{2})
\]</span></p>
<p>where <span class="math inline">\(\hat{\delta} = \frac{\Sigma_{i = 1}^{n} \delta_{i}}{n}\)</span> and <span class="math inline">\(\hat{\sigma}^{2} = \frac{\Sigma_{i = 1}^{n}(\delta_{i} - \hat{\delta})^{2}}{n - 1}\)</span></p>
</section>
<section id="time-to-code-this-up" class="level2">
<h2 class="anchored" data-anchor-id="time-to-code-this-up">Time to code this up!</h2>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> perf_counter</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RepeatedStratifiedKFold</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neural_network <span class="im">import</span> MLPClassifier</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> f1_score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To see this in action, the first thing we need is some data and repeated cross-validation predictions for two different algorithms.</p>
<p>We use sklearn to make a <em>moons</em> dataset:</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_moons(n_samples<span class="op">=</span><span class="dv">600</span>, noise<span class="op">=</span><span class="fl">0.4</span>, random_state<span class="op">=</span><span class="dv">23</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This has an equal number of labels of each class.</p>
<p>Now that we have the data, let’s run the repeated cross-validation for two models. Here we use a Random Forest and a neural network (MLPClassifier) classifier:</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>n_repetitions <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>n_folds <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>RSKF <span class="op">=</span> RepeatedStratifiedKFold(</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  n_splits<span class="op">=</span>n_folds, n_repeats<span class="op">=</span>n_repetitions, random_state<span class="op">=</span><span class="dv">23</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>model_1 <span class="op">=</span> <span class="st">"RF"</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>model_2 <span class="op">=</span> <span class="st">"MLP"</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> {</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  model_1: RandomForestClassifier(),</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  model_2: MLPClassifier(alpha<span class="op">=</span><span class="dv">1</span>, max_iter<span class="op">=</span><span class="dv">1_000</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>model_scores <span class="op">=</span> {}</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>model_times <span class="op">=</span> {}</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model_name, model <span class="kw">in</span> models.items():</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>  times_fit <span class="op">=</span> []</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  times_predict <span class="op">=</span> []</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>  scores <span class="op">=</span> []</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> train_indices, test_indices <span class="kw">in</span> RSKF.split(X, y):</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    X_train, X_test <span class="op">=</span> X[train_indices], X[test_indices]</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    y_train, y_test <span class="op">=</span> y[train_indices], y[test_indices]</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    time_start <span class="op">=</span> perf_counter()</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    clf <span class="op">=</span> model.fit(X_train, y_train)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    time_end <span class="op">=</span> perf_counter()</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    time_fit <span class="op">=</span> time_end <span class="op">-</span> time_start</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    time_start <span class="op">=</span> perf_counter()</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> clf.predict(X_test)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    time_end <span class="op">=</span> perf_counter()</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    time_predict <span class="op">=</span> time_end <span class="op">-</span> time_start</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    f1 <span class="op">=</span> f1_score(y_test, y_pred)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    times_fit.append(time_fit)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    times_predict.append(time_predict)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>    scores.append(f1)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>  model_scores[model_name] <span class="op">=</span> np.asarray(scores)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>  model_times[model_name] <span class="op">=</span> {</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>    <span class="st">"fit"</span>: times_fit,</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>    <span class="st">"predict"</span>: times_predict</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>  }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that we have the scores for each model, let’s perform the test. We’ll first need to compute the array of differences, <span class="math inline">\(\delta\)</span>, and then we’re in business.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># * create array of differences; we do model_2 (MLP) - model_1 (RF)</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>delta <span class="op">=</span> model_scores[model_2] <span class="op">-</span> model_scores[model_1]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="6">
<details>
<summary>Code for <code>compute_statistics</code></summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compute_statistics(</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  perf_differences, n_repetitions,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  ):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">  Given the m*k length array holding the scores for the m-repetitions of k-folds, will compute </span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">  the following statistics: the mean, the Nadeau-Bengio corrected </span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">  variance and the number of degrees of freedom for the t-distribution.</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>  mean <span class="op">=</span> np.mean(perf_differences)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>  variance <span class="op">=</span> np.var(perf_differences, ddof<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># * Now account for the correlations across measurements with the </span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># * Nadeau-Bengio correction of variance</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>  num_of_measurements <span class="op">=</span> perf_differences.size</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>  correlation <span class="op">=</span> n_repetitions <span class="op">/</span> num_of_measurements</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>  variance <span class="op">*=</span> <span class="dv">1</span> <span class="op">/</span> num_of_measurements <span class="op">+</span> correlation <span class="op">/</span> (<span class="dv">1</span> <span class="op">-</span> correlation)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> mean.item(), variance.item(), num_of_measurements <span class="op">-</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># * obtain the relevant statistics</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>mean, variance, dof <span class="op">=</span> compute_statistics(</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  perf_differences<span class="op">=</span>delta, n_repetitions<span class="op">=</span>n_repetitions</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="8">
<div class="cell-output cell-output-stdout">
<pre><code>t-distribution statistics:
mean 0.00451990557326873, 
variance 0.00015217969221592226, 
degrees of freedom 49.</code></pre>
</div>
</div>
<p>One useful thing we can do is to select a <em>region of practical equivalence, ROPE</em>. This is a region where the difference in performance can be considered <em>practically equivalent</em>, i.e.&nbsp;a difference lying within the ROPE is an inconsequential difference. Clearly the choice of ROPE is subjective and will depend on the <em>metric</em> and the <em>scale</em> we use to compare the algorithms in addition to our understanding of equivalence in the given situation. See <span class="citation" data-cites="kruske2013best">Kruske (<a href="#ref-kruske2013best" role="doc-biblioref">2013</a>)</span> and <span class="citation" data-cites="benavoli2017timeforachange">Benavoli et al. (<a href="#ref-benavoli2017timeforachange" role="doc-biblioref">2017</a>)</span> for more details.</p>
<p>Here we will say that a difference of 1% in performance between the two models makes the performance practically equivalent.</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code for <code>get_posteriors_from_t_distribution</code></summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_posteriors_from_t_distribution(</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  mean, variance, dof, rope<span class="op">=</span>(<span class="fl">0.0</span>, <span class="fl">0.0</span>), precision<span class="op">=</span><span class="dv">4</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">"""Compute and return probability mass to the left of the given rope, </span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co">  within the given rope and to the right of the given rope for a </span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">  t-distribution specified by the given mean, variance and degrees </span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">  of freedom. </span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">  NB: probabilities are computed from the cumulative Student distribution, not </span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">  from a sampled posterior.</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">  """</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># * Deal with the situation where the variance is very small by assigning entire </span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># * probability mass to the appropriate regions</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> np.isclose(variance, <span class="fl">0.0</span>):</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    prob_left <span class="op">=</span> <span class="bu">float</span>(mean <span class="op">&lt;</span> rope[<span class="dv">0</span>])</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    prob_right <span class="op">=</span> <span class="bu">float</span>(mean <span class="op">&gt;</span> rope[<span class="dv">1</span>])</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>  <span class="co"># * Otherwise compute the probability for the specified t-distribution.</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>: </span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    std <span class="op">=</span> np.sqrt(variance)</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    prob_left <span class="op">=</span> stats.t.cdf(rope[<span class="dv">0</span>], dof, loc<span class="op">=</span>mean, scale<span class="op">=</span>std)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    prob_right <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> stats.t.cdf(rope[<span class="dv">1</span>], dof, loc<span class="op">=</span>mean, scale<span class="op">=</span>std)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    prob_centre <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> prob_left <span class="op">-</span> prob_right</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> [<span class="bu">round</span>(p, precision) <span class="cf">for</span> p <span class="kw">in</span> [prob_left, prob_centre, prob_right]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># * Select a Region of practical equivalence:</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>ROPE <span class="op">=</span> (<span class="op">-</span><span class="fl">0.01</span>, <span class="fl">0.01</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>prob_model_1_better, prob_rope, prob_model_2_better <span class="op">=</span> get_posteriors_from_t_distribution(</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  mean<span class="op">=</span>mean, variance<span class="op">=</span>variance, dof<span class="op">=</span>dof, rope<span class="op">=</span>ROPE</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="cell-output cell-output-stdout">
<pre><code>P(RF &gt; MLP) = 0.1224, 
P(RF ~ MLP) = 0.5481, 
P(RF &lt; MLP) = 0.3294</code></pre>
</div>
</div>
<p>And what’s nicer, we can look at the distribution as the matching prior returns a posterior that is a t-distribution:</p>
<div class="cell" data-execution_count="12">
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-13-output-1.png" width="768" height="515"></p>
</div>
</div>
<p>Since the posterior distribution informs us about the relative credibility values across the reals, from the posterior we get the uncertainty in the estimate. From this we can get a whole lot of useful information, for instance the Highest Density Intervals (HDIs), the mode, the mean, etc. Furthermore, equipped with the posterior distribution and the region of practical equivalence we can:</p>
<ol type="1">
<li>Estimate the posterior probability of a reasonable null hypothesis, i.e.&nbsp;if the difference in performance is within a couple of percentage points they may well be considered equivalent. This will be given by the area within the rope region, above denoted by <span class="math inline">\(P(RF \sim MLP | D)\)</span>.</li>
<li>Estimate the posterior probability that one model is better than the other, i.e.&nbsp;<span class="math inline">\(P(RF &gt; MLP | D)\)</span> and <span class="math inline">\(P(RF &lt; MLP | D)\)</span>. These will be given by the areas on either side of the ROPE.</li>
<li>Represent effect size and uncertainty.</li>
</ol>
</section>
<section id="cost-sensitive-decisions" class="level2">
<h2 class="anchored" data-anchor-id="cost-sensitive-decisions">Cost sensitive decisions</h2>
<p>While we will be dealing with this in more detail in a separate blog post, let’s have a first stab.</p>
<p>In the real world, it is usually the case that we want to reason and make decisions about situations based on the concept of <em>cost</em>. The choice of the cost measure should depend on how the system is going to be used, rather than on any inherent specification of the training process. The issue with doing this is that it is hard. It is hard because specifying a cost-aware loss function is non-trivial, because cost-specifications are domain specific, and becuase even in the case of roughly knowing what the costs are, using this information is hard, i.e.&nbsp;the specified weigthed cost may be a difficult objective for optimisers to work with. However if we can specify costs then decision making based on these would be the best way to work as this allows one to take into consideration the utility of the decision that will be made.</p>
<p>In our situation, in order to do cost-sensitive analysis/decision making, all we need is to specify a cost function – we won’t need to run an optimisation on this objective function. This is a function that defines the loss (or cost) we incur in making a given decision (e.g.&nbsp;the wrong decision). A typical example is whether to give more importance to a false positive or a false negative. For our given situation and for the sake of exposition, let’s assume that we are interested in the time taken to fit the model as we will need to do it often. (Also because in our example, the models actually take the same time to predict.) We find that</p>
<div class="cell" data-execution_count="13">
<div class="cell-output cell-output-stdout">
<pre><code>Median time to fit RF is 0.1138 s, 
Median time to fit MLP is 0.7345 s, 
Ratio MLP / RF is 6.45</code></pre>
</div>
</div>
<p>That is, MLP is a lot slower to fit than RF. There are three decisions we can make</p>
<ol type="1">
<li>RF is better than MLP</li>
<li>RF is equivalent to MLP</li>
<li>RF is worse than MLP</li>
</ol>
<p>We consider the following cost-matrix:</p>
<table class="table">
<colgroup>
<col style="width: 21%">
<col style="width: 21%">
<col style="width: 27%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>RF is better</th>
<th>are equivalent</th>
<th>MLP is better</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Choose RF</td>
<td>0</td>
<td>-5</td>
<td>2</td>
</tr>
<tr class="even">
<td>Choose MLP</td>
<td>7</td>
<td>5</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>where the <span class="math inline">\((i, j)\)</span>th entry is the cost incurred by making decision <span class="math inline">\(i\)</span> when <span class="math inline">\(j\)</span> is correct. Here we have a <span class="math inline">\(2 \times 3\)</span> matrix as we only consider the options of selecting either one model or the other, no abstention, or anything else.</p>
<p>In this case we have:</p>
<ul>
<li>cost of choosing the Random Forest is:
<ul>
<li>0 if it is better,</li>
<li>-5 if they are equivalent as we save compute time,</li>
<li>2 if MLP is better, as we would lose performance</li>
</ul></li>
<li>cost of choosing the MLPClassifier is:
<ul>
<li>7 if RF is better because we pay for computational and performance cost,</li>
<li>5 if they are equivalent as we add to the compute time,</li>
<li>0 if MLP is indeed better</li>
</ul></li>
</ul>
<p>The <em>expected cost</em> can then be obtained by multiplying the cost matrix with the relevant posterior probabilities. In this case, the relevant probabilities are <span class="math inline">\(P(RF &gt; MLP | D)\)</span>, <span class="math inline">\(P(RF \sim MLP | D)\)</span> and <span class="math inline">\(P(RF &lt; MLP | D)\)</span>.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>cost_matrix <span class="op">=</span> np.array([</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">0.</span>, <span class="op">-</span><span class="fl">5.</span>, <span class="fl">2.</span>],</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  [<span class="fl">7.</span>, <span class="fl">5.</span>, <span class="fl">0.</span>],</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>probabilities <span class="op">=</span> np.array([</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  prob_model_1_better, </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  prob_rope, </span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>  prob_model_2_better</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>expected_cost <span class="op">=</span> cost_matrix.dot(probabilities)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="15">
<div class="cell-output cell-output-stdout">
<pre><code>
Cost of deciding on RF: -2.0817

Cost of deciding on MLP: 3.5973</code></pre>
</div>
</div>
<p>The lowest cost would determine the optimal decision. We see that we would incur a significant cost in choosing MLP over RF. Of course, we could have made things even more extreme by specifying more aggressive costs. And further, we could have extended the possibilities, e.g.&nbsp;adding a row for “no decision made”.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-benavoli2017timeforachange" class="csl-entry" role="doc-biblioentry">
Benavoli et al. 2017. <span>“Time for a Change: A Tutorial for Comparing Multiple Classifiers Through Bayesian Analysis.”</span>
</div>
<div id="ref-bouckaert2003choosing" class="csl-entry" role="doc-biblioentry">
Bouckaert, RR. 2003. <span>“Choosing Between Two Learning Algorithms Based on Calibrated Tests.”</span> In <em>ICML</em>, 3:51–58.
</div>
<div id="ref-corani2015bayesian" class="csl-entry" role="doc-biblioentry">
Corani, G, and A Benavoli. 2015. <span>“A Bayesian Approach for Comparing Cross-Validated Algorithms on Multiple Data Sets.”</span> <em>Machine Learning</em> 100 (2): 285–304.
</div>
<div id="ref-kruske2013best" class="csl-entry" role="doc-biblioentry">
Kruske, JK. 2013. <span>“Bayesian Estimation Supersedes the t Test.”</span> <em>Journal of Experimental Psychology: General</em> 142 (2): 573–603.
</div>
<div id="ref-nadeaubengio2003" class="csl-entry" role="doc-biblioentry">
Nadeau, C, and Y Bengio. 2003. <span>“Inference for the Generalization Error.”</span> <em>Machine Learning</em> 52: 239–81.
</div>
</div></section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div quarto-reuse="quarto-reuse" class="quarto-appendix-contents"><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="ergodicedamame/blog" data-repo-id="R_kgDOG9LH-w" data-category="Comments" data-category-id="DIC_kwDOG9LH-84CN-s8" data-mapping="title" data-reactions-enabled="0" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>